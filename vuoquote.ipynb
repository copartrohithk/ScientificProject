{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import index\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def get_VueQuote_details(index, df_row):\n",
    "    \"\"\" Fetches VueQuote details for a given lot_number, with retry logic, and includes API URL. \"\"\"\n",
    "    lot_number = df_row.get('lot_nbr', 'Unknown')  # Ensure lot_number is always available\n",
    "    url = f\"https://c-services-vip.copart.com/visionpqservice/v1/proquote/lot_number/{lot_number}\"\n",
    "\n",
    "    print(f\"Processing lot_number: {lot_number}\")\n",
    "\n",
    "    payload = {}\n",
    "    files = {}\n",
    "    headers = {\n",
    "        'requester': 'Sales_Analytics',\n",
    "        'correlationId': 'Sales_Analytics',\n",
    "        'proquoteNotRequired': 'false',\n",
    "        'country': 'USA',\n",
    "        'Authorization': 'bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6ImdhdXRoLWtleS1pZC0xIn0.eyJlbnRpdHlfcm9sZXMiOlsiQWxsTXlDb3BhcnRVc2VycyIsIk9rdGEgTUZBIERhbGxhcyBIUSIsImdjcC1jYnEtdXNtYXJ0LXZpZXdzIiwiT2t0YSBTU08gZm9yIENvbmN1ciBHbG9iYWwiLCJWUE4gQ29ycCBXRkgiLCJnY3AtZGF0YXBsYXRmb3JtLXVzbWFydC12aWV3cy1waWl0YWciLCJnY3AtYWxsdXNlcnMiLCJNYWlsLVNpZ25hdHVyZXMtVVMiLCJWUE4gQ29ycCBHcm91cCIsImdjcC1jYnEtdXN2aWV3cy12MSIsIk9rdGEgTUZBIGZvciBPcHMgUG9ydGFsIC0gQ29ycG9yYXRlIiwiT0tUQSBTU08gVGFibGVhdSBVQVQgVGVzdCIsIkVtcGxveWVlIElEIC0gUmVzdHJpY3RlZCIsImdjcC1jYnEtYW5hbHl0aWNzLXVzZXJzIiwiT0tUQSBTU08gZm9yIFRhYmxlYXUgQ29udHJpYnV0b3IiLCJQaGlzaGluZyBDYW1wYWlnbiBHcm91cCAtIFVTIiwiZ2NwLWNicS11a21hcnQtdmlld3MiLCJDb25mbHVlbmNlIFVzZXJzIiwiT2t0YSBTU08gZm9yIENlbnRlclN0YWdlIiwiSmVua2lucyBVc2VycyIsIk9LVEEgU1NPIGZvciBEYXlmb3JjZSIsIlNpZ25hdHVyZTM2NSAtIFVTIiwiWnNjYWxlciBCSSBHcm91cCIsIkplbmtpbnMgUHJvamVjdCBBZG1pbnMiLCJCcml2byBQcm92aXNpb25pbmciXSwiZW50aXR5X25hbWUiOiJQdXNoa2FyYWogSmFkaGF2IiwiZW50aXR5X21hbmFnZXJfbWFpbCI6InR5bGVyLmFtb3NAY29wYXJ0LmNvbSIsImVudGl0eV9tYW5hZ2VyX2NvcGFydF9pZCI6IlVTQTI3NjE1IiwidXNlcl9uYW1lIjoicHVzaGthcmFqLmphZGhhdkBjb3BhcnQuY29tIiwiZW50aXR5X29mZmljZSI6IkNvcnBvcmF0ZSIsImVudGl0eV9pZCI6InB1amFkaGF2IiwiZW50aXR5X2F1dGhfc2NvcGUiOiJQaGlzaGluZyBDYW1wYWlnbiBHcm91cCAtIFVTIiwiY2xpZW50X2lkIjoiYXV0aF9wcm94eSIsImVudGl0eV9mYWNpbGl0eV9pZCI6IjcwMCIsImVudGl0eV9tYWlsIjoicHVzaGthcmFqLmphZGhhdkBjb3BhcnQuY29tIiwiZW50aXR5X3R5cGUiOiJlbXBsb3llZSIsInNjb3BlIjpbImNvcGFydC5yZWFkIiwiY29wYXJ0LndyaXRlIiwibG9naW4iLCJjb3BhcnQuZnVsbF9hY2Nlc3MiLCJjb3BhcnQ6ZGVmYXVsdCBzY29wZSJdLCJlbnRpdHlfY291bnRyeSI6IlVTIiwiZW50aXR5X3N0YXR1cyI6IkFDVElWRSIsImV4cCI6MTc0MjU3NTE3OSwianRpIjoiNWVkYmEwNjYtMDQwYS00MmUzLTlmOTUtZTU4YjY1MDM2MjdlIiwiZW50aXR5X2VtcGxveWVlX2NvcGFydF9pZCI6IlVTQTI4MzAxIn0.lkW-H1DBQvS7nyrHOjjPBx6lQQA-EkNS-qFt1DoqhYMu18be8ZBTHRzNHVlirR8psDoIlZavlNIYtGQL8ethznKc9yRVJiLNkJL8-_sDC5ho2n_ICMT_3tcgPbBNUvwFMhjJCpCsfxF0eLSm1f32ne7rhRh4wFS8SJJQH-nbbeeWrAjwOjr7uX8IUS7wz7gYt2U7LI94rAFdFjEujmEjKm7Sd7bNOx4virDCBapWMj6_BIrjF-KtiHJ4y8MJuhcWAsQEV1GpTPgBgs9-jXGhn57p7lse2ju2kTons4pYaCKCknKs8fmzTAbPHJgmzwIhpZiB4MJ8kkif91BjyBmyBA'\n",
    "    }\n",
    "\n",
    "    max_retries = 3  # Maximum retry attempts\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.request(\"GET\", url, headers=headers, data=payload, files=files)\n",
    "\n",
    "            # Check if response is empty or status code is not 200\n",
    "            if response.status_code == 200 and response.text.strip():\n",
    "                try:\n",
    "                    response_json = response.json()\n",
    "                    response_json['api_call'] = url  # Append the API call URL\n",
    "                    return index, response_json\n",
    "                except requests.exceptions.JSONDecodeError:\n",
    "                    print(f\"Invalid JSON response for lot_number {lot_number}: {response.text}\")\n",
    "                    return index, {\"lot_nbr\": lot_number, \"error\": \"Invalid JSON\", \"api_call\": url}\n",
    "            else:\n",
    "                print(f\"Request failed for lot_number {lot_number} (status: {response.status_code})\")\n",
    "                return index, {\"lot_nbr\": lot_number, \"error\": \"Request Failed\", \"api_call\": url}\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API request error for lot_number {lot_number}: {e}\")\n",
    "\n",
    "        # Exponential backoff\n",
    "        time.sleep(2 ** attempt)\n",
    "\n",
    "    return index, {\"lot_nbr\": lot_number, \"error\": \"Max retries reached\", \"api_call\": url}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load CSV file containing lot numbers\n",
    "    in_df = pd.read_csv(r'/Users/pujadhav/Downloads/pure_insurance 1.csv')\n",
    "    in_df = in_df.fillna('')  # Handle missing values\n",
    "\n",
    "    rows = list(in_df.to_dict(orient='records'))  # Convert to list\n",
    "\n",
    "    # Using multithreading for API calls, ensuring order is preserved\n",
    "    results_dict = {}\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        future_to_index = {executor.submit(get_VueQuote_details, i, row): i for i, row in enumerate(rows)}\n",
    "        for future in as_completed(future_to_index):\n",
    "            index, result = future.result()  # Get index and result\n",
    "            results_dict[index] = result  # Store in dictionary\n",
    "\n",
    "    # Sort results by index to maintain original order\n",
    "    sorted_results = [results_dict[i] for i in sorted(results_dict.keys())]\n",
    "\n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    result_df = pd.DataFrame(sorted_results)\n",
    "\n",
    "    # Flatten nested JSON data if necessary\n",
    "    if 'requestDetails' in result_df.columns:\n",
    "        request_details_df = pd.json_normalize(result_df['requestDetails'])  # Flatten nested JSON\n",
    "        result_df = result_df.drop(columns=['requestDetails']).join(request_details_df)  # Merge flattened data\n",
    "\n",
    "    # **Flatten nested JSON fields**\n",
    "    # If JSON has nested keys, use json_normalize()\n",
    "    if any(isinstance(val, dict) for val in result_df.iloc[0].values):\n",
    "        result_df = pd.json_normalize(result_df.to_dict(orient='records'))\n",
    "\n",
    "    # Save final DataFrame to CSV\n",
    "    output_path = r'/Users/pujadhav/Downloads/Rohith_Request_VQ_output.csv'\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Process completed! Output saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
